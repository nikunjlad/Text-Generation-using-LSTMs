{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generate.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1IL-QcPXF32Udpg-wFEHcPTLdbHi3csFX","authorship_tag":"ABX9TyN64JXLoCvQEYereWaihRsW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PzwMg9mWGKtt","colab_type":"code","colab":{}},"source":["!pip install -U -q pyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oc0r0AGxGNKd","colab_type":"code","colab":{}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdIAQr1dIV6z","colab_type":"code","colab":{}},"source":["import os\n","os.listdir()\n","os.chdir(\"drive/My Drive/Colab Notebooks/Text-Generation/PyTorch/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o5zap47JDfHf","colab_type":"code","colab":{}},"source":["import argparse\n","import torch\n","import data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqDDRKPGDnJJ","colab_type":"code","colab":{}},"source":["# parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 Language Model')\n","\n","# # Model parameters.\n","# parser.add_argument('--data', type=str, default='./data/wikitext-2',\n","#                     help='location of the data corpus')\n","# parser.add_argument('--checkpoint', type=str, default='./model.pt',\n","#                     help='model checkpoint to use')\n","# parser.add_argument('--outf', type=str, default='generated.txt',\n","#                     help='output file for generated text')\n","# parser.add_argument('--words', type=int, default='1000',\n","#                     help='number of words to generate')\n","# parser.add_argument('--seed', type=int, default=1111,\n","#                     help='random seed')\n","# parser.add_argument('--cuda', action='store_true',\n","#                     help='use CUDA')\n","# parser.add_argument('--temperature', type=float, default=1.0,\n","#                     help='temperature - higher will increase diversity')\n","# parser.add_argument('--log-interval', type=int, default=100,\n","#                     help='reporting interval')\n","# args = parser.parse_args()\n","\n","args = {}\n","args[\"data\"] = \"./data/paul_graham/\"\n","args[\"checkpoint\"] = \"./model3.pt\"\n","args[\"outf\"] = \"generated3.txt\"\n","args[\"words\"] = 1000\n","args[\"seed\"] = 1111\n","args[\"cuda\"] = True\n","args[\"temperature\"] = 1.0\n","args[\"log_interval\"] = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFpsmCn7DvMN","colab_type":"code","colab":{}},"source":["# Set the random seed manually for reproducibility.\n","torch.manual_seed(args[\"seed\"])\n","if torch.cuda.is_available():\n","    if not args[\"cuda\"]:\n","        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n","\n","device = torch.device(\"cuda\" if args[\"cuda\"] else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eqjmSm-GDxXz","colab_type":"code","outputId":"c677943b-49bf-4e66-cfe1-f0613ce06699","executionInfo":{"status":"ok","timestamp":1585531936189,"user_tz":240,"elapsed":17751,"user":{"displayName":"Nikunj Lad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgD0pS1NL2dBJiFQz8hU82Sdb-UZb7jgwPjLw5f=s64","userId":"16906182826931650917"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["if args[\"temperature\"] < 1e-3:\n","    parser.error(\"--temperature has to be greater or equal 1e-3\")\n","\n","with open(args[\"checkpoint\"], 'rb') as f:\n","    model = torch.load(f).to(device)\n","model.eval()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNModel(\n","  (drop): Dropout(p=0.65, inplace=False)\n","  (encoder): Embedding(32929, 1500)\n","  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)\n","  (decoder): Linear(in_features=1500, out_features=32929, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"toBeqL5_Dzoq","colab_type":"code","outputId":"d3b6a8ba-2986-460d-b560-ab7f3ef1f7b7","executionInfo":{"status":"ok","timestamp":1585531945694,"user_tz":240,"elapsed":6627,"user":{"displayName":"Nikunj Lad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgD0pS1NL2dBJiFQz8hU82Sdb-UZb7jgwPjLw5f=s64","userId":"16906182826931650917"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["corpus = data.Corpus(args[\"data\"])\n","ntokens = len(corpus.dictionary)\n","\n","is_transformer_model = hasattr(model, 'model_type') and model.model_type == 'Transformer'\n","if not is_transformer_model:\n","    hidden = model.init_hidden(1)\n","input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n","\n","with open(args[\"outf\"], 'w') as outf:\n","    with torch.no_grad():  # no tracking history\n","        for i in range(args[\"words\"]):\n","            if is_transformer_model:\n","                output = model(input, False)\n","                word_weights = output[-1].squeeze().div(args[\"temperature\"]).exp().cpu()\n","                word_idx = torch.multinomial(word_weights, 1)[0]\n","                word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n","                input = torch.cat([input, word_tensor], 0)\n","            else:\n","                output, hidden = model(input, hidden)\n","                word_weights = output.squeeze().div(args[\"temperature\"]).exp().cpu()\n","                word_idx = torch.multinomial(word_weights, 1)[0]\n","                input.fill_(word_idx)\n","\n","            word = corpus.dictionary.idx2word[word_idx]\n","\n","            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n","\n","            if i % args[\"log_interval\"] == 0:\n","                print('| Generated {}/{} words'.format(i, args[\"words\"]))\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["| Generated 0/1000 words\n","| Generated 100/1000 words\n","| Generated 200/1000 words\n","| Generated 300/1000 words\n","| Generated 400/1000 words\n","| Generated 500/1000 words\n","| Generated 600/1000 words\n","| Generated 700/1000 words\n","| Generated 800/1000 words\n","| Generated 900/1000 words\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S0x0xU3tJFFd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}